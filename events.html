<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Events - Audio Processing Workshops and Challenges</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>

    <header>
        <div class="header-container">
            <img src="assets/umd.png" alt="UMD Logo" class="logo-left">
            <h1>Events, Challenges & Workshops</h1>
            <img src="assets/gamma_logo-2.png" alt="GAMMA Lab Logo" class="logo-right">
        </div>
    </header>

    <!-- Navigation Bar -->
    <nav class="navbar">
        <ul>
            <li><a href="index.html"><i class="fas fa-home"></i> Home</a></li>
            <li><a href="research.html"><i class="fas fa-flask"></i> Research</a></li>
            <li><a href="index.html#people"><i class="fas fa-users"></i> People</a></li>
            <li><a href="index.html#updates"><i class="fas fa-bullhorn"></i> Updates</a></li>
            <li><a href="events.html"><i class="fas fa-calendar-alt"></i> Events</a></li>
        </ul>
    </nav>

    <!-- Events Section -->
    <section class="card-container">
        <!-- Event 1 -->
        <div class="card">
            <h2>SALMA Workshop @ ICASSP 2025</h2>
            <p><strong>Date:</strong> April 6-11, 2025</p>
            <p><strong>Location:</strong> Hyderabad, India</p>
            <p><strong>Description:</strong> The first Workshop on Speech and Audio Language Models (SALMA), co-located with IEEE ICASSP 2025, focuses on leveraging Large Language Models (LLMs) to advance speech and audio processing. The workshop aims to bring together researchers to explore effective methodologies for improving performance across various tasks in speech, audio, and music domains, including classification, generation, and retrieval.</p>
            <div class="buttons">
            <a href="https://salmaworkshop.github.io/" target="_blank" class="btn">Learn More</a>
        </div>
        </div>

        <!-- Event 2 -->
        <div class="card">
            <h2>JSALT Challenge and Summer School</h2>
            <p><strong>Date:</strong> June 9 - August 1, 2025</p>
            <p><strong>Location:</strong> Brno, Czechia</p>
            <p><strong>Description:</strong> The 2025 Jelinek Workshop on Speech and Language Technologies (JSALT) is an eight-week residential summer research workshop. It brings together international teams to work intensively on challenging problems in speech and language engineering, machine learning, and artificial intelligence. The workshop fosters collaboration and has a lasting influence through publications, software, and data produced. We propose <a href="https://jsalt2025.fit.vut.cz/summer-workshop#advancing-expert-level-reasoning-and-understanding-in-large-audio-models">Advancing Expert-Level Reasoning and Understanding in Large Audio Language Models</a> which is a workshop focused on advancing expert-level understanding and complex reasoning in audio-language models. The team, drawn from several universities and industry in the US, Europe and Asia, and with students and senior professionals from various disciplines, will allow us to achieve these goals.</p>
            <div class="buttons">
            <a href="https://jsalt2025.fit.vut.cz/summer-workshop#advancing-expert-level-reasoning-and-understanding-in-large-audio-models" target="_blank" class="btn">Learn More</a>
        </div>
        </div>

        <!-- Event 3 -->
        <div class="card">
            <h2>DCASE 2025 Challenge</h2>
            <p><strong>Challenge Period:</strong> April 1 - June 15, 2025</p>
            <p><strong>Workshop Dates:</strong> October 30-31, 2025</p>
            <p><strong>Location:</strong> Barcelona, Spain</p>
            <p><strong>Description:</strong> The IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2025 focuses on developing signal processing methods to automatically extract information from everyday environmental sounds. The challenge includes tasks such as acoustic scene classification, anomalous sound detection, and audio question answering. The associated workshop provides a venue for researchers to present and discuss their results. We propose <a href="https://dcase.community/challenge2025/index#audio-question-answering"> The Audio Question Answering (AQA) </a> task which focuses on advancing question-answering capabilities in the realm of “interactive audio understanding,” covering both general acoustic events and knowledge-heavy sound information within a single track. The AQA task encourages participants to develop systems that can accurately interpret and respond to complex audio-based questions (i.e., (A), (B), or (C) option), requiring models to process and reason across diverse audio types. Such systems could be useful in many applications, including audio-text and multimodal model evaluation, as well as building interactive audio-agent models for the audio research communities and beyond. Reproducible baselines will include one resource-efficient computing setting (i.e., single 8GB RAM); direct using enterprise API for challenge entry is prohibited.</p>
            <div class="buttons">
            <a href="https://dcase.community/challenge2025/index#audio-question-answering" target="_blank" class="btn">Learn More</a>
        </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 UMD GAMMA Lab</p>
    </footer>

</body>
</html>